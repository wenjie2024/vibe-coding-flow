import json
import shutil
import time
from pathlib import Path
from typing import Dict, Any, List

from vibe.core.adapter_interface import RuleBundle, WritePlan
from rich.console import Console
from vibe.config.paths import RULES_DIR, TEMPLATES_DIR
from vibe.utils.files import read_template

console = Console()

def build_rule_bundle(context: Dict[str, Any]) -> RuleBundle:
    """
    Builds the agnostic rule bundle from the project context.
    This generates the standard rules that will be projected to IDEs.
    """
    bundle = RuleBundle()
    
    # 1. 00_project_context.md (Pointer)
    bundle.rules["00_project_context.md"] = (
        "<!-- This file is auto-generated by Vibe. DO NOT EDIT. -->\n"
        "<!-- It serves as a pointer for the AI agent to finding the source of truth. -->\n\n"
        "Please refer to the following files for project context:\n\n"
        "- **Product Context**: `.context/productContext.md` (Requirements & Goals)\n"
        "- **System Patterns**: `.context/systemPatterns.md` (Architecture & Tech Stack)\n"
        "- **Active Status**: `.context/activeContext.md` (Current Task & Progress)\n"
    )
    
    # Load Standard Templates
    try:
        # Fixed Rules
        bundle.rules["00a_project_environment.md"] = read_template("00a_project_environment.md", RULES_DIR)
        bundle.rules["00b_llm_integration.md"] = read_template("00b_llm_integration.md", RULES_DIR)
        bundle.rules["02_tech_stack_standards.md"] = read_template("02_tech_stack_standards.md", RULES_DIR)
        
        # 01 Workflow
        bundle.rules["01_workflow.md"] = read_template("01_workflow_plan_first.md", RULES_DIR) # Key normalized
        
        # 03 Output
        bundle.rules["03_output_format.md"] = read_template("03_output_format.md", RULES_DIR)

        # 02 Stack (Heuristic Selection)
        system_patterns = context.get("system_patterns", "").lower()
        rule_02_template_name = "02_stack_python_fastapi.md"  # Default
        
        if "django" in system_patterns:
            rule_02_template_name = "02_stack_python_django.md"
        elif "node" in system_patterns or "express" in system_patterns:
            rule_02_template_name = "02_stack_nodejs_express.md"
        elif "react" in system_patterns or "vite" in system_patterns:
            rule_02_template_name = "02_stack_react_vite.md"
        elif "go" in system_patterns or "gin" in system_patterns:
            rule_02_template_name = "02_stack_go_gin.md"
        elif "telegram" in system_patterns or "bot" in system_patterns:
            rule_02_template_name = "02_stack_telegram_bot.md"
        elif "postgres" in system_patterns:
            rule_02_template_name = "02_stack_postgresql.md"
            
        try:
            content = read_template(rule_02_template_name, RULES_DIR)
        except SystemExit:
            # Fallback
            content = read_template("02_stack_python_fastapi.md", RULES_DIR)
            
        # We normalize the key to 02_stack.md for consistency across adapters
        bundle.rules["02_stack.md"] = content
        
        # Load Scripts
        from vibe.config.paths import SCRIPTS_DIR
        if SCRIPTS_DIR.exists():
            for script_file in SCRIPTS_DIR.glob("*.py"):
                try:
                    bundle.scripts[script_file.name] = script_file.read_text(encoding="utf-8")
                except Exception as ex:
                    console.print(f"[yellow]Failed to load script {script_file.name}: {ex}[/yellow]")

        # 4. Load Project Skills (Dynamic)
        SKILLS_DIR = TEMPLATES_DIR / "skills"
        if SKILLS_DIR.exists():
            for skill_dir in SKILLS_DIR.iterdir():
                if skill_dir.is_dir():
                    skill_name = skill_dir.name
                    skill_files = {}
                    
                    # Walk the skill directory
                    for file_path in skill_dir.rglob("*"):
                        if file_path.is_file():
                            try:
                                # Rel path inside skill dir (e.g. "scripts/analyze.py")
                                rel_path = file_path.relative_to(skill_dir)
                                # Handle .j2 extension (strip it for the target filename)
                                target_name = str(rel_path)
                                if target_name.endswith(".j2"):
                                    target_name = target_name[:-3]
                                
                                # Read content (simple read for now, no complex Jinja context yet)
                                content = file_path.read_text(encoding="utf-8")
                                skill_files[target_name] = content
                            except Exception as ex:
                                console.print(f"[yellow]Failed to load skill file {file_path}: {ex}[/yellow]")
                    
                    if skill_files:
                        bundle.skills[skill_name] = skill_files

        
    except Exception as e:
        console.print(f"[bold red]Error building rule bundle:[/bold red] {e}")
    
    return bundle

def _merge_json_smart(existing_content: str, new_content: str, filename: str) -> str:
    """Smart merge for JSON files based on filename."""
    try:
        ex_data = json.loads(existing_content)
        new_data = json.loads(new_content)
        
        if filename.endswith("settings.json"):
            # Merge permissions.allow
            ex_perms = ex_data.get("permissions", {})
            new_perms = new_data.get("permissions", {})
            
            ex_allow = ex_perms.get("allow", [])
            new_allow = new_perms.get("allow", [])
            
            if not isinstance(ex_allow, list): ex_allow = []
            if not isinstance(new_allow, list): new_allow = []
            
            # Union while preserving order
            final_allow = list(ex_allow)
            for item in new_allow:
                if item not in final_allow:
                    final_allow.append(item)
            
            # Reconstruct
            if "permissions" not in ex_data: ex_data["permissions"] = {}
            ex_data["permissions"]["allow"] = final_allow
            return json.dumps(ex_data, indent=2)

        elif filename.endswith("mcp.json"):
            # Merge mcpServers keys
            ex_servers = ex_data.get("mcpServers", {})
            new_servers = new_data.get("mcpServers", {})
            
            for k, v in new_servers.items():
                if k not in ex_servers:
                    ex_servers[k] = v
            
            ex_data["mcpServers"] = ex_servers
            return json.dumps(ex_data, indent=2)
            
        return new_content # Fallback (Overwrite)

    except Exception as e:
        console.print(f"[yellow]‚ö†Ô∏è  JSON Merge failed for {filename}: {e}[/yellow]")
        return existing_content

def apply_write_plan(plan: WritePlan, project_root: Path, mode: str = "safe", dry_run: bool = False):
    """
    Executes the write plan with the specified safety mode.
    """
    if dry_run:
        console.print("[bold yellow]DRY RUN: No changes will be written to disk.[/bold yellow]")
    
    backup_dir = project_root / ".vibe" / "backup" / str(int(time.time()))
    files_backed_up = False
    
    for rel_path, content in plan.files.items():
        full_path = project_root / rel_path
        status_msg = f"[green]Would create:[/green] {rel_path}"
        
        # --- Pre-Execution Verification ---
        if full_path.exists():
            status_msg = f"[yellow]Would overwrite/merge:[/yellow] {rel_path}"
            
            # For Dry Run, we just print status
            if dry_run:
                console.print(status_msg)
                continue

            # Real Execution checks
            is_json_merge = rel_path.endswith(".json") and (rel_path.endswith("settings.json") or rel_path.endswith("mcp.json"))
            is_git_append = (rel_path == ".gitignore")
            
            # If not a mergeable/appendable file, and mode is safe -> Skip
            if mode == "safe" and not is_json_merge and not is_git_append:
                console.print(f"[yellow]‚ö†Ô∏è  Skipping existing file:[/yellow] {rel_path} (Use --force to overwrite)")
                continue

        elif dry_run:
            console.print(status_msg)
            continue

        # --- Execution ---
        final_content = content
        should_write = True
        
        if full_path.exists():
            # Use sig to handle potential BOM from Windows editors
            original_text = full_path.read_text(encoding="utf-8-sig")
            
            if rel_path.endswith("settings.json") or rel_path.endswith("mcp.json"):
                console.print(f"[dim]Merging {rel_path}...[/dim]")
                final_content = _merge_json_smart(original_text, content, rel_path)
                # Note: merge is always applied even in safe mode
                
            elif rel_path == ".gitignore":
                if content.strip() not in original_text:
                    final_content = original_text + "\n" + content
                    console.print(f"[dim]Appending to .gitignore...[/dim]")
                else:
                    should_write = False # Already there
                    
            elif mode == "force":
                 # Backup existing file before overwrite
                if not files_backed_up:
                    backup_dir.mkdir(parents=True, exist_ok=True)
                    files_backed_up = True
                
                backup_path = backup_dir / rel_path
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                try:
                    shutil.copy2(full_path, backup_path)
                    console.print(f"[blue]üì¶ Backed up {rel_path}[/blue]")
                except Exception as e:
                    console.print(f"[bold red]Failed to backup {rel_path}: {e}[/bold red]")
                    continue
        
        if should_write:
            try:
                full_path.parent.mkdir(parents=True, exist_ok=True)
                # Ensure directory exists for new files
                full_path.parent.mkdir(parents=True, exist_ok=True)
                with open(full_path, "w", encoding="utf-8") as f:
                    f.write(final_content)
                console.print(f"[green]‚úÖ Created/Updated:[/green] {rel_path}")
            except Exception as e:
                console.print(f"[bold red]Failed to write {rel_path}: {e}[/bold red]")
